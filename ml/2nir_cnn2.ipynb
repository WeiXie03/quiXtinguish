{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data and label coordinates\n",
    "\n",
    "\n",
    "\n",
    "# Create label maps from the coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd972615278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplt\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "loader = transforms.Compose([\n",
    "  #transforms.Resize(img_size),\n",
    "  #transforms.CenterCrop(img_size),\n",
    "  transforms.ToTensor(),\n",
    "]) \n",
    "\n",
    "def load_image(filename, volatile=False):\n",
    "    \"\"\"\n",
    "    Simple function to load and preprocess the image.\n",
    "\n",
    "    1. Open the image.\n",
    "    2. Scale/crop it and convert it to a float tensor.\n",
    "    3. Convert it to a variable (all inputs to PyTorch models must be variables).\n",
    "    4. Add another dimension to the start of the Tensor (b/c VGG expects a batch).\n",
    "    5. Move the variable onto the GPU.\n",
    "    \"\"\"\n",
    "    image = Image.open(filename).convert('RGB')\n",
    " \n",
    "    '''\n",
    "    #increase contrast\n",
    "    hist, bins = np.histogram(image.flatten(),256,[0,256])\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "    cdf_m = np.ma.masked_equal(cdf,0)\n",
    "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "    image = cdf[image]\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(3.0)\n",
    "    '''\n",
    "    \n",
    "    image_tensor = loader(image).float()\n",
    "    return image_tensor\n",
    "    #image_var = Variable(image_tensor, volatile=volatile).unsqueeze(0)\n",
    "    #return image_var.cuda\n",
    "\n",
    "plt.imshow(load_image('data/2nirtrienvs/undistorted/210_left.jpg').numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "CPU_DEBUG = False\n",
    "\n",
    "# Setup the model\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "device = torch.device(\"cpu\" if CPU_DEBUG else \"cuda\")\n",
    "\n",
    "class CoarseFireDetector(nn.Module):\n",
    "    # Your code goes here\n",
    "    def __init__(self):\n",
    "        super(CoarseFireDetector, self).__init__()\n",
    "                                                #input_channels, output_channels, kernel_size\n",
    "        self.layers = nn.ModuleList([nn.Conv2d(3, 16, 5, stride=1, bias=True)])\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Conv2d(16, 16, 5, stride=2, bias=True))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Conv2d(16, 8, 5, stride=1, bias=True))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Conv2d(8, 8, 3, stride=1, bias=True))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Conv2d(8, 1, 3, stride=1, bias=True))\n",
    "        #self.layers.append(nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = input \n",
    "        #print(input.dim())\n",
    "        if input.dim() == 3:\n",
    "            out = out.unsqueeze(0)\n",
    "            for layer in self.layers:\n",
    "                out = layer(out)\n",
    "            return out.squeeze()\n",
    "        else:\n",
    "            for layer in self.layers:\n",
    "                out = layer(out)\n",
    "            return out \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1544202130060/work/aten/src/THC/THCGeneral.cpp:51",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-10182759f106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcf_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoarseFireDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/2nirtrienvs/undistorted/210_left.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/2nirtrienvs/undistorted/210_left.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl37/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    161\u001b[0m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (30) : unknown error at /opt/conda/conda-bld/pytorch_1544202130060/work/aten/src/THC/THCGeneral.cpp:51"
     ]
    }
   ],
   "source": [
    "cf_detector = CoarseFireDetector().cuda()\n",
    "out = cf_detector(load_image('data/2nirtrienvs/undistorted/210_left.jpg').cuda())\n",
    "print(out.size())\n",
    "plt.imshow(load_image('data/2nirtrienvs/undistorted/210_left.jpg').numpy().transpose(1,2,0))\n",
    "plt.show()\n",
    "plt.imshow(out.cpu().detach().numpy())\n",
    "label_shape = out.cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "def show_torch_img(tensor):\n",
    "    plt.imshow(tensor.detach().cpu().numpy().transpose(1,2,0))\n",
    "    #plt.show()\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# Training Dataset\n",
    "data = \"data/2nirtrienvs/undistorted\"\n",
    "metadp = \"metadata.dat\"\n",
    "metadata = None\n",
    "with open(os.path.join(data, metadp), 'rb') as metadf:\n",
    "    print(os.path.join(data, metadp))\n",
    "    metadata = pickle.load(metadf)\n",
    "    #metadata = dict((k,metadata[k]) for k in range(478))\n",
    "    #pp.pprint(metadata)\n",
    "\n",
    "# load the input imgs\n",
    "input_imgs = []\n",
    "coords = []\n",
    "for i, num in enumerate(metadata):\n",
    "    #print(metadata[num])\n",
    "    for side in 'left', 'right':\n",
    "        print(metadata[num][side]['img_path'])\n",
    "        if 'ml' in metadata[num][side]['img_path']:\n",
    "            input_imgs.append(load_image(metadata[num][side]['img_path'][3:]))\n",
    "        else:\n",
    "            input_imgs.append(load_image(metadata[num][side]['img_path']))\n",
    "        coords.append(metadata[num][side]['coords'])\n",
    "    #print(coords[-2])\n",
    "    #show_torch_img(input_imgs[-2])\n",
    "    #show_torch_img(input_imgs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x, y = np.meshgrid(np.linspace(-1,1,9), np.linspace(-1,1,9))\n",
    "d = np.sqrt(x*x+y*y)\n",
    "sigma, mu = 0.4, 0.0\n",
    "g = np.exp(-( (d-mu)**2 / ( 2.0 * sigma**2 ) ) )\n",
    "print(\"2D Gaussian-like array:\")\n",
    "#print(g)\n",
    "plt.imshow(g)\n",
    "#print(g.shape)\n",
    "\n",
    "labels = []\n",
    "for num, img in enumerate(input_imgs):\n",
    "    #print(num)\n",
    "    # Create labels\n",
    "    #print(metadata[num])\n",
    "    #print(input_imgs[num])\n",
    "    label = np.zeros(label_shape)\n",
    "    coord = coords[num]\n",
    "    _, input_imgs_w, input_imgs_h = input_imgs[num].numpy().shape\n",
    "    #print(input_imgs_w, input_imgs_h)\n",
    "    #print(label_shape)\n",
    "    \n",
    "    if coord == None:\n",
    "        pass\n",
    "    elif coord[0] == None or coord [1] == None:\n",
    "        pass\n",
    "    else:\n",
    "    #print(coord)\n",
    "        central = (int(coord[0]/input_imgs_w*label_shape[0]), \n",
    "                        int(coord[1]/input_imgs_h*label_shape[1]))\n",
    "        #print(central)\n",
    "        #print(central)\n",
    "        for i in range(-4, 5):\n",
    "            for j in range(-4, 5):\n",
    "                lx = min(max(central[1]+i, 0),label_shape[0]-1)\n",
    "                ly = min(max(central[0]+j, 0),label_shape[1]-1)\n",
    "                label[lx, ly] += g[i+4, j+4]\n",
    "        #show_torch_img(img)\n",
    "    #plt.show()\n",
    "    #plt.imshow(label)\n",
    "    #plt.show()\n",
    "    #show_torch_img\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import FloatTensor\n",
    "from torch import optim\n",
    "\n",
    "cf_detector = CoarseFireDetector().cuda()\n",
    "\n",
    "optimizer = optim.Adam(cf_detector.parameters(), lr = 0.001) \n",
    "\n",
    "n_epochs = 3\n",
    "for i in range(n_epochs):\n",
    "    for j, (img, label) in enumerate(zip(input_imgs, labels)):\n",
    "        if (j > 24 and j != 134 and j < 280) or (j > 390 and j < 424):\n",
    "        #if j > 24 and j != 134 or j < 424:\n",
    "            optimizer.zero_grad()\n",
    "            out = cf_detector(img.cuda().unsqueeze(0))\n",
    "            #print(out.size())\n",
    "            weights = np.zeros_like(label)\n",
    "            weights[label<0.001] = 1.2\n",
    "            weights[label>=0.001] = 1.0\n",
    "            loss = torch.mean(FloatTensor(weights).cuda()*(FloatTensor(label).cuda()-out)**2)\n",
    "            #loss = torch.sum((FloatTensor(label).cuda()-out)**2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errdists = []\n",
    "trupos, falpos, truneg, falneg = 0, 0, 0, 0\n",
    "\n",
    "for ind, (img, label) in enumerate(zip(input_imgs, labels)):\n",
    "    if ind <= 24 or ind == 134 or ind >= 424:\n",
    "        show_torch_img(img)\n",
    "        '''\n",
    "        outline = plt.Circle(coords[ind], 5, color='green', fill=False)\n",
    "        ax = plt.gca()\n",
    "        ax.add_patch(outline)\n",
    "        plt.axis('scaled')\n",
    "        '''\n",
    "        plt.show()\n",
    "        \n",
    "        #show the ML prediction(probability of fire at all points on the image)\n",
    "        ml_pred = cf_detector.cuda()(img.cuda()).cpu().detach().numpy()\n",
    "        plt.imshow(ml_pred, cmap=\"seismic\", vmin=0, vmax=0.001)\n",
    "        \n",
    "        #get coords of point most likely to be fire according to ML\n",
    "        (predy, predx) = np.unravel_index(np.argmax(ml_pred), ml_pred.shape)\n",
    "        print('ml prediction on current plot', (predy, predx))\n",
    "        #NOTE: above line prints (y, x), NOT (x, y)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "        #show the human-labelled coordinates\n",
    "        plt.imshow(label, cmap = \"seismic\", vmin=0, vmax=1.0)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "        #calculate real coords on new plot/grid\n",
    "        x_factor = label.shape[0]/input_imgs[ind].shape[1]\n",
    "        y_factor = label.shape[1]/input_imgs[ind].shape[2]\n",
    "        if coords[ind] == None or None in coords[ind]:\n",
    "            print('no fire')\n",
    "            if ml_pred.max() > 0.04:\n",
    "                falpos += 1\n",
    "            elif ml_pred.max() <= 0.04:\n",
    "                truneg += 1\n",
    "        else:\n",
    "            realy, realx = coords[ind][1]*y_factor, coords[ind][0]*x_factor\n",
    "            #print('real coords on current plot', (realy, realx))\n",
    "            #NOTE: above line prints (y, x), NOT (x, y)\n",
    "            \n",
    "            #confusion matrix\n",
    "            if ml_pred.max() <= 0.04:\n",
    "                falneg += 1\n",
    "            elif ml_pred.max() > 0.04:\n",
    "                trupos += 1\n",
    "            \n",
    "            #calculate straight-line distance btwn real coords and ML predictions\n",
    "            #errdist = ( (x_factor*(realx-predx))**2 + (y_factor*(realy-predy))**2 )**0.5\n",
    "            errdist = ( (predx/x_factor-coords[ind][0])**2 + (predy/y_factor-coords[ind][1])**2 )**0.5\n",
    "            errdists.append(errdist)\n",
    "            #print('distance btwn real and predicted coords on OG image =', errdist, 'pixels')\n",
    "            #print('distance btwn real and predicted coords on OG image =', np.asarray(errdist)*1.4/1000, 'millimeters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram of distances error\n",
    "print(errdists)\n",
    "#plt.hist(errdists, bins=list(range(1,7)))\n",
    "plt.hist(errdists, bins=14)\n",
    "plt.xlabel('Distance of Error(px)')\n",
    "plt.ylabel('Count')\n",
    "#plt.yticks(range(5))\n",
    "plt.show()\n",
    "\n",
    "print('mean distance =', sum(errdists)/len(errdists), 'px')\n",
    "\n",
    "print('true positives', ':', trupos)\n",
    "print('false positives', ':', falpos)\n",
    "print('true negatives', ':', truneg)\n",
    "print('false negatives', ':', falneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
